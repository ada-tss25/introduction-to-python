{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ada-tss25/introduction-to-python/blob/main/Day02-DL_concepts_and_PyTorch/Day02-Intro_to_Pytorch_afternoon_codealong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCdj-_pnBqhA"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1cXtXdAcwedVDbapmz1pj_hULsQrhEcff\" width=\"500\"/>\n",
        "\n",
        "---\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://pytorch.org/assets/images/pytorch-logo.png\" alt=\"drawing\" width=\"100\"/>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "<h1 style=\"text-align: center;\"> Introduction to Pytorch for Deep Learning</h1>\n",
        "\n",
        "\n",
        "\n",
        "In this introduction to PyTorch for deep learning, we will dive into certain packages and utilities of the library made to facilitate data handling and training opertations. We will explore similar concepts that were seen in the previous lectures, but in a different way. We will specifically focus on the functions of ``Dataset`` and ``Dataloader`` objects and their roles, also exploring adjacent functionlities for data splitting, pre-processing, and analysis. We will also discuss the basic training workflow and how ``PyTorch`` integrates these different steps. We must consider that ``PyTorch`` is an extensive library, and these lectures are designed to introduce you to its main concepts, particularly the ones that are useful for the completion of this module. With the links and references below, we encourage you to further explore the library as you see fit.\n",
        "\n",
        "\n",
        "#### **Morning contents/agenda**\n",
        "1. Basic functionalities: Tensor Handling like Numpy Arrays\n",
        "\n",
        "2. Data Handling with ``Torchvision``\n",
        "\n",
        "3. Batch Handling with ``Dataloader``\n",
        "\n",
        "4. Review of the ``Pytorch`` training workflow for a classification task\n",
        "\n",
        "5. Customisation of ``Dataset`` classes\n",
        "\n",
        "\n",
        "#### **Afternoon contents/agenda**\n",
        "\n",
        "1. Understanding the basics:\n",
        "- [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA&ab_channel=3Blue1Brown)\n",
        "\n",
        "- [But what is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk&t=1s&ab_channel=3Blue1Brown)\n",
        "\n",
        "- [What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=2s&ab_channel=3Blue1Brown)\n",
        "\n",
        "2. Exercise 2\n",
        "\n",
        "#### **Learning Outcomes**\n",
        "\n",
        "1. Get acquainted with common ``Torchvision`` datasets and integrate them into a ``Pytorch`` workflow\n",
        "\n",
        "2. Learn the basic usage of ``torchvision.transforms``\n",
        "\n",
        "3. Understand the difference between a ``Dataset`` and a ``Dataloader`` and how to integrate them\n",
        "\n",
        "4. Understand the ``Pytorch`` workflow for training a classification model\n",
        "\n",
        "5. Learn to create custom ``Dataset`` classes\n",
        "\n",
        "7. Learn to access the ``Pytorch`` documentation\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "30KsuqBPBzld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85f43cc-2b6a-4512-ca13-faeb7b946f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pBG1w14BBqhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef62c48-dfc2-4ad7-e274-8e552fe63d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda installed! Running on GPU 0 Tesla T4!\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-summary progressbar2 -q\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def set_device(device=\"cpu\", idx=0):\n",
        "    if device != \"cpu\":\n",
        "        if torch.cuda.device_count() > idx and torch.cuda.is_available():\n",
        "            print(\"Cuda installed! Running on GPU {} {}!\".format(idx, torch.cuda.get_device_name(idx)))\n",
        "            device=\"cuda:{}\".format(idx)\n",
        "        elif torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "            print(\"Cuda installed but only {} GPU(s) available! Running on GPU 0 {}!\".format(torch.cuda.device_count(), torch.cuda.get_device_name()))\n",
        "            device=\"cuda:0\"\n",
        "        else:\n",
        "            device=\"cpu\"\n",
        "            print(\"No GPU available! Running on CPU\")\n",
        "    return device\n",
        "\n",
        "device = set_device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1NmjeisNz3"
      },
      "source": [
        "## Recap of Classes in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B_Nleqp8vNtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732639ba-5e29-4bb8-865a-e5e3f33efd56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is my attribute\n",
            "This is my method\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "my_object = MyClass()\n",
        "\n",
        "class MyClass:\n",
        "  def __init__(self):\n",
        "    self.my_attribute = \"this is my attribute\"\n",
        "    return\n",
        "\n",
        "  def my_method(self):\n",
        "        return \"This is my method\"\n",
        "\n",
        "my_object = MyClass()\n",
        "print(my_object.my_attribute)\n",
        "print(my_object.my_method())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCYOrhYYC8Ek"
      },
      "source": [
        "Magic methods in Python are special methods that enable customisation of the behaviour of built-in operations in Python classes, such as arithmetic operations, comparisons, and object creation. Examples include ``__init__`` for initialising objects, ``__str__`` for defining string representation, and ``__add__`` for implementing addition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IdFoI0n4sBHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d480bb-3bc3-4846-fb9a-abe39a7483ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            " __str__\n",
            "my custom class\n",
            "\n",
            " __call__\n",
            "49\n",
            "\n",
            " __len__\n",
            "10\n",
            "\n",
            " __call__\n",
            "0\n",
            "\n",
            " __setitem__\n",
            "\n",
            " __getitem__\n",
            "[10]\n",
            " \n",
            " ------ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Magic methods\n",
        "class MyClass:\n",
        "    def __init__(self, N): # What the object does when it is first created\n",
        "        print(\"__init__\")\n",
        "        self.my_attribute = [i for i in range(N)]\n",
        "        return\n",
        "\n",
        "    def __str__(self): # What the object returns when it is cast into a string object\n",
        "        print(\"\\n __str__\")\n",
        "        return \"my custom class\"\n",
        "\n",
        "    def __call__(self, x): # What the object does when it is called as a function\n",
        "        print(\"\\n __call__\")\n",
        "        return x**2\n",
        "\n",
        "    def __len__(self): # What the object returns when it's length is queried\n",
        "        print(\"\\n __len__\")\n",
        "        return len(self.my_attribute)\n",
        "\n",
        "    def __getitem__(self, i): # What the object returns when it is indexed\n",
        "        print(\"\\n __getitem__\")\n",
        "        return self.my_attribute[i]\n",
        "\n",
        "    def __setitem__(self, i, val): # How the object is modefied after index assignement\n",
        "        print(\"\\n __setitem__\")\n",
        "        self.my_attribute[i] = val\n",
        "        return\n",
        "\n",
        "# How to use each magic method:\n",
        "my_object = MyClass(10) # __init__\n",
        "print(my_object.my_attribute)\n",
        "\n",
        "### # __str__\n",
        "print(my_object)\n",
        "\n",
        "### # __call__\n",
        "print(my_object(7))\n",
        "\n",
        "### # __len__\n",
        "print(len(my_object))\n",
        "\n",
        "### # __getitem__\n",
        "print(my_object(0))\n",
        "\n",
        "### # __setitem__\n",
        "my_object[0] = [10]\n",
        "### # __getitem__\n",
        "print(my_object[0])\n",
        "print(\" \\n ------ \\n\")\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skf91SrkU2Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fLQ-wagSU2e8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agr7OyKiJcHX"
      },
      "source": [
        "In Python, ``self`` is a reference to the instance of the class, allowing access to its attributes and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "L6lcC2HyJSwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83941f24-9b63-4323-a3e9-2fcf5fa1dafd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Magic methods\n",
        "class MyClass:\n",
        "    def __init__(self): # What the object does when it is first created\n",
        "        self.my_attribute = 10\n",
        "        return\n",
        "\n",
        "    def __call__(self, x): # What the object does when it is called as a function\n",
        "        return x**2 * self.my_attribute\n",
        "\n",
        "\n",
        "my_object = MyClass()\n",
        "my_object(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-8Gl_ksKd_9"
      },
      "source": [
        "An important concept in OOD is *Inheritance*.\n",
        "\n",
        "Classes can inherit code and attributes from other classes to reuse shared logic while creating a distinct hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZvELaduEUz9Z",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721fec72-9398-4a38-a00e-c306e3a5faae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creates an animal\n",
            "Max 2 None\n",
            "creates a dog\n",
            "Creates an animal\n",
            "<__main__.Animal object at 0x7eabe974a060>\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Parent class\n",
        "class Animal:\n",
        "    def __init__(self, name, age):\n",
        "        print(\"Creates an animal\")\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.kind = None\n",
        "        return\n",
        "\n",
        "    def speak(self): # Each inherited class is responsible for implementing its own `speak` method\n",
        "        raise NotImplementedError\n",
        "\n",
        "dog = Animal(\"Max\", age=2)\n",
        "print(dog.name, dog.age, dog.kind)\n",
        "\n",
        "class Dog(Animal):\n",
        "  def __init__(self, name, age):\n",
        "    print(\"creates a dog\")\n",
        "    super().__init__(name, age)\n",
        "    self.kind = dog\n",
        "dog = Dog(\"mAX\", age=3)\n",
        "print(dog.kind)\n",
        "###\n",
        "###\n",
        "###\n",
        "print(\"---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-HQCtJxU1M5"
      },
      "outputs": [],
      "source": [
        "# Child class\n",
        "class Dog(Animal):\n",
        "    def __init__(self, name, age, ###):\n",
        "        print(\"Creates a dog\")\n",
        "        ###\n",
        "        self.coat = ###\n",
        "        self.kind = ###\n",
        "        self.breed = ###\n",
        "        return\n",
        "\n",
        "    def speak(self):\n",
        "        return ###\n",
        "\n",
        "###\n",
        "###\n",
        "###\n",
        "print(\"---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk_by3MjsJiZ"
      },
      "source": [
        "Let's look how this plays out in deep learning. Suppose we want to model a layer with weights and biases that act in an input to produce an output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zh8QjLpTsK8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce52777-3b4d-4bfc-e739-7855b3cbbf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer 1\n",
            "Hidden Layer weights: [0.5, -0.2]\n",
            "Hidden Layer bias: 0.1\n",
            "Base Hidden Layer output: 1.5\n",
            "\n",
            "Hidden Layer 2\n",
            "Hidden Layer weights: [1.0, 1.0]\n",
            "Hidden Layer bias: -1.0\n",
            "Base Hidden Layer output: 6.0\n"
          ]
        }
      ],
      "source": [
        "# Parent/Base class\n",
        "class HiddenLayer:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # simple weighted sum (linear combination)\n",
        "        total = sum(w * i for w, i in zip(self.weights, inputs)) + self.bias\n",
        "        return total\n",
        "\n",
        "\n",
        "# Try it\n",
        "l1 = HiddenLayer([0.5, -0.2], 0.1)\n",
        "print(\"Hidden Layer 1\")\n",
        "print(\"Hidden Layer weights:\", l1.weights)\n",
        "print(\"Hidden Layer bias:\", l1.bias)\n",
        "print(\"Base Hidden Layer output:\", l1.forward([4, 3]))\n",
        "\n",
        "l2 = HiddenLayer([1.0, 1.0], -1.0)\n",
        "print(\"\\nHidden Layer 2\")\n",
        "print(\"Hidden Layer weights:\", l2.weights)\n",
        "print(\"Hidden Layer bias:\", l2.bias)\n",
        "print(\"Base Hidden Layer output:\", l2.forward([4, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCTNsoFTsoXO"
      },
      "source": [
        "In neural networks, **activation functions** change how outputs behave.\n",
        "\n",
        "By itself, the layer we created can only combine inputs as a linear model\n",
        "\n",
        "But by applying a non-linear function to the layer's output, activation functions allow layers to capture more complex, non-linear patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DpwfuIYnsqmR"
      },
      "outputs": [],
      "source": [
        "class ReLUHiddenLayerScratch():\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "\n",
        "    def relu(self, x):\n",
        "      return max(0,x)\n",
        "        ### # a non-linear piecewise function\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        total = sum(w * i for w, in zip(self.weights, inputs)) + self.bias **2\n",
        "        return self.relu(total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tKfOjT2usr50"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inheritance allows us to re-use code and build in modularity\n",
        "class ReLUHiddenLayer(HiddenLayer):\n",
        "    def __init__(self, weights, biases):\n",
        "        super().__init__(weights, biases)\n",
        "\n",
        "    def relu(self, x):\n",
        "        return max(0, x)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        total = super().forward(inputs)      # use parent's forward()\n",
        "        return self.relu(total)              # apply ReLU activation\n",
        "\n",
        "\n",
        "# Derived class: Sigmoid neuron\n",
        "class SigmoidHiddenLayer(HiddenLayer):\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 +math.exp(-x))  # a non-linear S-shaped function\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        total = super().forward(inputs)\n",
        "        return self.sigmoid(total)  # apply sigmoid activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Rv8qhH9YstHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9717e720-91ed-4428-efb2-ff985054e12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base:    -1.5\n",
            "ReLU:    0\n",
            "Sigmoid: 0.18242552380635635\n"
          ]
        }
      ],
      "source": [
        "# Compare outputs\n",
        "inputs = [-2, 3]\n",
        "base = HiddenLayer([0.5, -0.2], 0.1)\n",
        "relu = ReLUHiddenLayer([0.5, -0.2], 0.1)\n",
        "sigmoid = SigmoidHiddenLayer([0.5, -0.2], 0.1)\n",
        "\n",
        "print(\"Base:   \", base.forward(inputs))\n",
        "print(\"ReLU:   \", relu.forward(inputs))\n",
        "print(\"Sigmoid:\", sigmoid.forward(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBUItVP0FpiR"
      },
      "source": [
        "### Why and When to Use Classes? (Object-Oriented Programming)\n",
        "\n",
        "- **Organisation:** Classes provide a structured way to group related data and behaviours, making code more intuitive and easier to follow.\n",
        "\n",
        "- **Modularity:** Through encapsulation, classes create self-contained objects, simplifying debugging and enhancing collaboration in team projects.\n",
        "\n",
        "- **Reusability and Productivity:** By leveraging inheritance, existing code can be reused and extended, reducing duplication and saving development time.\n",
        "\n",
        "- **Scalability and Maintainability:** Classes allow functionalities to be developed and upgraded independently, making them particularly advantageous for systems that are dynamic or require frequent updates.\n",
        "\n",
        "\n",
        "\n",
        "PyTorch is predominantly object-oriented for model organisation and design. It is mainly developed around the ``nn.Module`` base class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "A3PKAUi1tUes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ed3d31-13fc-4bd6-c27a-8f617e85cc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomNeuron output:\n",
            " tensor([[0.],\n",
            "        [0.]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class CustomLayer(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()                      # call parent nn.Module constructor\n",
        "        self.linear = nn.Linear(input_size, 1)  # built-in linear layer (weights and biases are handled internally)\n",
        "        self.relu = nn.ReLU()                   # built-in ReLU activation, a class also inheriting from nn.Module\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.linear(x)      # weighted sum + bias -- equivalent to calling HiddenLayer.forward()\n",
        "        return self.relu(z)     # apply ReLU -- equivalent to ReLUHiddenLayer.forward()\n",
        "\n",
        "# Test run\n",
        "layer = CustomLayer(3)  # 3 input feature\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                    [4.0, 5.0, 6.0]])  # batch of 2\n",
        "outuput = layer(x) # equivalent to layer.forward(x)\n",
        "print(\"CustomNeuron output:\\n\", outuput)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VFVFe53ttuz"
      },
      "source": [
        "Let's have a look at our model class from the previous lectures and tie it all together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD-HBV8jyKpO"
      },
      "outputs": [],
      "source": [
        "# Child class inherited from nn.Module\n",
        "class simpleFFN(nn.Module):\n",
        "\n",
        "  # Initialise with a few parameters that will define our model\n",
        "  def __init__(self, input_size, hidden_size_1=100, hidden_size_2=50, output_size=10):\n",
        "\n",
        "    # This is an older syntax for simply super().__init__()\n",
        "    super(simpleFFN, self).__init__()\n",
        "\n",
        "    # Attributes are layers and activation of our model\n",
        "    # Note they are also instantiated objects of a class\n",
        "    self.hidden_1 = nn.Linear(input_size, hidden_size_1, bias=False)\n",
        "    self.hidden_2 = nn.Linear(hidden_size_1, hidden_size_2, bias=False)\n",
        "    self.output = nn.Linear(hidden_size_2, output_size, bias=False)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  # 'forward' is a required method of nn.Module derived classes\n",
        "  def forward(self, X):\n",
        "    print(\"Running model forward pass\")\n",
        "\n",
        "    # Cascade the variable X through the model calling each layer instance\n",
        "    z1 = self.hidden_1(X.flatten(start_dim=1))\n",
        "    a1 = self.activation(z1)\n",
        "    z2 = self.hidden_2(a1)\n",
        "    a2 = self.activation(z2)\n",
        "    z3 = self.output(a2)\n",
        "    a3 = self.activation(z3)\n",
        "    return a3\n",
        "\n",
        "model = simpleFFN(input_size=1*28*28, hidden_size_1=200, hidden_size_2=50, output_size=10) #out 10 classes\n",
        "print(model) #  __str__\n",
        "\n",
        "# The 'forward' function functions as __call__\n",
        "print(model(torch.rand(1,1,28,28))) # __call__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fkg1x0PFg3Ro"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaGxK_4mr-9i"
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6smNB4gIgEv"
      },
      "source": [
        "## Basic functionalities: Tensor Handling like Numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUoHynl7Igl0"
      },
      "outputs": [],
      "source": [
        "my_data = [i for i in range(100)]\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rllkPr8epQBm"
      },
      "outputs": [],
      "source": [
        "###\n",
        "my_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKfDS3kapQBm"
      },
      "outputs": [],
      "source": [
        "### # shares storage with original tensor\n",
        "my_reshaped_tensor, my_reshaped_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCElflRApQBm"
      },
      "outputs": [],
      "source": [
        "###\n",
        "rand_tensor.mean(), rand_tensor.std(), rand_tensor.max(), rand_tensor.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKwxa2hbpQBm"
      },
      "outputs": [],
      "source": [
        "###\n",
        "print(rand_tensor_sq.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmdMicvlpQBm"
      },
      "source": [
        "Pytorch also contains some functional programming for tensor operations and low-level customisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g6sk4OYpQBm"
      },
      "outputs": [],
      "source": [
        "torch.linalg.inv(rand_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN2bHZthpQBm"
      },
      "outputs": [],
      "source": [
        "torch.fft.fftn(rand_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVSEqiLtBqhD"
      },
      "source": [
        "## Data Handling with Torchvision's KMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN_erM55BqhD"
      },
      "source": [
        "[``Torchvision``](https://pytorch.org/vision/stable/index.html) is one of many support libraries for the ``Pytorch`` project. It provides a range of popular models (pre-trained or not) and datasets, as well as image transformations that are useful for computer vision problems. Because it is a support library, its integration to ``Pytorch`` is native and straigth-forward, as we will see below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Wd0rWcBqhD"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "train_dataset = ###\n",
        "test_dataset = ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkfYNzSPBqhD"
      },
      "outputs": [],
      "source": [
        "print(type(train_dataset), \"\\n\")\n",
        "print(train_dataset, \"\\n\")\n",
        "print(dir(train_dataset), \"\\n\") # Information held in the dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCmYlWdIBqhE"
      },
      "outputs": [],
      "source": [
        "class_to_idx = ###\n",
        "print(class_to_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xv-4YFGBqhE"
      },
      "source": [
        "* The method ``__getitem__`` is called when indexing samples within Pytorch Datasets\n",
        "\n",
        "* For this dataset class, ``__getitem__`` returns two variables: the image and its target label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzq2kDYxBqhE"
      },
      "outputs": [],
      "source": [
        "sample =  ###\n",
        "print(sample, \"\\n\")\n",
        "\n",
        "plt.imshow(###)\n",
        "plt.title(###)\n",
        "plt.show(###)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz5-a9YtBqhE"
      },
      "source": [
        "#### Let's visualise a few samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32TUHGojBqhE"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "idxs = torch.randint(low=0, high=len(train_dataset), size=(6,))\n",
        "fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
        "for i, idx in enumerate((idxs)):\n",
        "    img, target = ###\n",
        "    axs[i].imshow(###)\n",
        "    axs[i].set_title(str(target) + \" / \" + class_to_idx[target])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0-WgUldBqhE"
      },
      "source": [
        "* For convenience, let's change the format of the image from ``PIL`` to a ``torch.tensor`` object\n",
        "\n",
        "* We will do so by using the ``torchvision.transforms`` module\n",
        "\n",
        "* A list of transforms is often packaged into a ``Compose`` container\n",
        "\n",
        "* Pytorch's standard practice is to apply such transformations inside the method ``__getitem__``\n",
        "\n",
        "* It doesn't modify the data in storage, but it will be applied whenever the dataset is indexed\n",
        "\n",
        "\n",
        "* This circumvents the need of using pre-processing scripts to generate and store a processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE0q4fnIBqhE"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor\n",
        "transform = Compose([ToTensor(),]) # Compose a list of transformations\n",
        "\n",
        "train_dataset = ###\n",
        "test_dataset = ###\n",
        "\n",
        "sample = ##\n",
        "img, target = sample\n",
        "\n",
        "print(img.shape, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3JgrKjEBqhF"
      },
      "source": [
        "* Using a ``ToTensor`` transformation is equivalent to calling ``TensorDataset``, as seen in the previous lecture. However, ``TensorDataset`` requires all data to be loaded into memory, which is not often feasible. Using the transformation allows the data to be transformed into ``torch.tensor`` objects as the data is accessed.\n",
        "\n",
        "* Other transformations from the ``torch.transforms`` module can be found in its documentation [here](https://pytorch.org/vision/0.9/transforms.html)\n",
        "\n",
        "* These include ``Normalize``, ``Pad``, ``RandomCrop``, ``Resize``, etc..\n",
        "\n",
        "* There is even an option to create custom transforms with ``transforms.Lambda``. Let's have a look"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7iTXf_eBqhF"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Lambda\n",
        "\n",
        "def add_noise(x, alpha=0.1):\n",
        "    return x + alpha*torch.rand_like(x)\n",
        "\n",
        "\n",
        "transform = Compose([ToTensor(),\n",
        "                     ###\n",
        "                     ])\n",
        "\n",
        "train_dataset = ###\n",
        "test_dataset = ###\n",
        "\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS7XvyYuBqhF"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "idxs = torch.randint(low=0, high=len(train_dataset), size=(6,))\n",
        "fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
        "for i, idx in enumerate((idxs)):\n",
        "    img, target = ###\n",
        "    axs[i].imshow(img[0], cmap=\"gray\") # imshow expects W x H x C format\n",
        "    axs[i].set_title(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoO7AE2fBqhF"
      },
      "source": [
        "* For now, all we need is the simple transformation of the dataset to ``torch.Tensor`` objects to allow ``PyTorch`` handling, and the standardisation of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDSMo6vKBqhF"
      },
      "outputs": [],
      "source": [
        "print(\"min/max:\", ###)\n",
        "print(\"mean: \", ###)\n",
        "print(\"std: \", ###)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qdee4bWrBqhF"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Normalize\n",
        "\n",
        "transform = Compose([ToTensor(), # In this transformation the data is scaled from [0, 1], see documentation\n",
        "                     Normalize(0.19176216423511505, 0.3483428359031677), # This transforms applies a Z-score normalisation\n",
        "                     ])\n",
        "\n",
        "train_dataset = ###\n",
        "test_dataset = ###\n",
        "\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kIXSnhsBqhF"
      },
      "outputs": [],
      "source": [
        "print(\"min/max:\", ###)\n",
        "print(\"mean: \", ###)\n",
        "print(\"std: \", ###)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhEx7Fa2BqhF"
      },
      "source": [
        "* Why is the data not standardised?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWynZd-yBqhF"
      },
      "source": [
        "## Batch Handling with ``DataLoader``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYWuUXkYBqhF"
      },
      "source": [
        "* The process of training in Pytorch relies on batch management of a particular dataset\n",
        "\n",
        "* This is done using the [``Dataloader``](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) module, which is responsible for accessing a [``Dataset``](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) derived object and handling it according to our needs\n",
        "\n",
        "* In a way, the ``Dataloader`` and ``Dataset`` objects complement one another. The ``Dataset`` object handles **data** processing, whereas the ``Dataloader`` handles **batch** processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzL7XUBFBqhG"
      },
      "outputs": [],
      "source": [
        "batch_size = ### # The batch size\n",
        "num_workers = ### # Subprocess for loading the data\n",
        "\n",
        "train_loader = ###\n",
        "\n",
        "print(train_loader)\n",
        "print(train_loader.__dict__) # Information held by the dataloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxO84IHjBqhG"
      },
      "source": [
        "#### \"The ``DataLoader`` object combines a dataset and a sampler, and provides an iterable over the given dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A-zhbpLBqhG"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "train_batch_sample, train_batch_targets = ### # syntax for directly iterating over the data loader\n",
        "print(train_batch_sample.shape, train_batch_targets.shape)\n",
        "\n",
        "# Visualise batch\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "batch_grid = ###\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(batch_grid[0], cmap=\"gray\") # index because make_grid transforms grayscale images to RGB\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print(train_batch_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK4ChMEEBqhG"
      },
      "source": [
        "* Fetching the next batch of the ``train_loader`` iterator returns 32 samples and 32 corresponding target labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyFexoTEBqhG"
      },
      "outputs": [],
      "source": [
        "print(\"min/max:\", ###)\n",
        "print(\"mean: \", ###)\n",
        "print(\"std: \", ###)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beCa8_BqsB3h"
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev91FjR6BqhG"
      },
      "source": [
        "## Training workflow: ``Dataset`` and  ``Dataloader`` in Perspective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BeiHWxbBqhG"
      },
      "source": [
        "* Let's begin by splitting our training dataset into training and validation using ``StratifiedShuffleSplit`` and ``Subset``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myok3FEhBqhG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "shuffler = ###\n",
        "train_idxs, valid_idxs = [(train_idx, valid_idx) for train_idx, valid_idx in shuffler][0]\n",
        "\n",
        "# Split data with Subset (does not require data to be loaded into memory, it limits the range of which __getitem__ can be called)\n",
        "from torch.utils.data import Subset\n",
        "valid_dataset = ###\n",
        "train_dataset = ###\n",
        "\n",
        "# Confirm split ratio and no overlapping idxs\n",
        "print(\"train ratio:\", ###)\n",
        "print(\"valid ratio:\", ###)\n",
        "print(\"no overlapping values\", ###)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNeCmNKiBqhG"
      },
      "outputs": [],
      "source": [
        "print(type(train_dataset))\n",
        "print(train_dataset.__dict__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62-XJb0IBqhG"
      },
      "source": [
        "* ``Subset`` is one of the many useful tools created by Pytorch to manipulate a ``Dataset`` object without creating copies. Other operations include concatenation and chaining, and can be found in the documentation [here](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "* We now need two dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "491FnehpBqhG"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 # The batch size\n",
        "num_workers = 0 # Subprocess for loading the data\n",
        "\n",
        "train_loader = ###\n",
        "\n",
        "valid_loader = ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZzWPklnBqhH"
      },
      "source": [
        "#### Let's now return to the simple feed-forward network from the previous lecture, with some custom modifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTg59noxBqhH"
      },
      "outputs": [],
      "source": [
        "class simpleFFN(nn.Module):\n",
        "  def __init__(self, ###):\n",
        "    super(simpleFFN, self).__init__()\n",
        "    self.hidden_1 = nn.Linear(###, ###, bias=False)\n",
        "    self.hidden_2 = nn.Linear(###, ###, bias=False)\n",
        "    self.output = nn.Linear(###, ###, bias=False)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    z1 = self.hidden_1(X)\n",
        "    a1 = self.activation(z1)\n",
        "    z2 = self.hidden_2(a1)\n",
        "    a2 = self.activation(z2)\n",
        "    z3 = self.output(a2)\n",
        "    a3 = self.activation(z3)\n",
        "    return a3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSVsel4nBqhH"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "model = ###\n",
        "\n",
        "# Check number of parameters\n",
        "nparam_layer1 = ###\n",
        "nparam_layer2 = ###\n",
        "nparam_layer3 = ###\n",
        "print(nparam_layer1 + nparam_layer2 + nparam_layer3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHYbC07UBqhH"
      },
      "source": [
        "* More conveniently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXbEU2onBqhH"
      },
      "outputs": [],
      "source": [
        "sum(###)  #.parameters() is a method inherited from the nn.Module base class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwdNbE-xBqhH"
      },
      "source": [
        "* Even more conveniently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XohN-SHKBqhH"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summ ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwxCE-hVBqhH"
      },
      "outputs": [],
      "source": [
        "# Test model input and output sizes with batch sample\n",
        "x = ###\n",
        "y = model(x).to(device)\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tyTcuvHBqhH"
      },
      "source": [
        "### The Training Workflow: Forward, Loss, Backpropagate, Optimise, Repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqgSHXJBqhH"
      },
      "source": [
        "* Now that we have our data loaders ready to be iterated, let's revisit the training workflow from the last lecture\n",
        "\n",
        "* The general steps for training a model are:\n",
        "    1. Peform a foward pass of the **batch** throught the model to get initial outputs\n",
        "\n",
        "    2. Compare the outputs with the desired targets using a difference ``metric`` to obtain a ``loss`` measure\n",
        "\n",
        "    3. Compute derivatives of all model weights and biases with respect to the loss using back propagation\n",
        "    \n",
        "    4. Take an optimisation step and repeat for next batch\n",
        "\n",
        "\n",
        "* Once the network goes through all batches, an ``epoch`` is concluded\n",
        "\n",
        "\n",
        "* Let's use [``Adam``](https://arxiv.org/abs/1412.6980) as optimiser and [``Cross-Entropy``](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as our metric\n",
        "\n",
        "\n",
        "* First we define our ``loss``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNaqbgpyBqhH"
      },
      "outputs": [],
      "source": [
        "criterion = ###\n",
        "print(criterion.__dict__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvRVml1DBqhH"
      },
      "source": [
        "* The optimiser is responsible for navigating the loss space towards the gradient direction, but it is **NOT** responsible for computing these gradients\n",
        "\n",
        "* Commonly, these gradients are calculated using the ``.backward()`` method, which makes use of automatic differention and the [computational graph](https://colah.github.io/posts/2015-08-Backprop/) to perform the operation.\n",
        "\n",
        "* The gradients computed are stored within each ``torch.tensor`` that defines a trainable parameter. In our case, this refers to each model parameter. At each optimisation step, the optimiser updates the values of such tensors in their gradient direction for a distance specified by the learning rate, along with other parameters (e.g. momentum, weight decay)\n",
        "\n",
        "* When constructing an optimsier, the two important things to specify are: 1) which parameters to optimise, and 2) the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkWmY_iqBqhH"
      },
      "outputs": [],
      "source": [
        "optimiser = ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMZQxAZxBqhI"
      },
      "outputs": [],
      "source": [
        "first_param_layer = ###\n",
        "print(first_param_layer.shape)\n",
        "print(first_param_layer)\n",
        "print(first_param_layer.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKZ0KcvUBqhI"
      },
      "source": [
        "### Training and Validation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOcWE-swBqhI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train(model, optimizer, criterion, data_loader):\n",
        "    ###\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for input, target in data_loader:\n",
        "        input, target = input.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output =   ###       # Forward pass, evaluation of model and construction of computational graph\n",
        "        loss = ###\n",
        "        ###               # Backpropagation to calculate the gradients of every parameter\n",
        "\n",
        "        train_loss += loss*input.size(0)\n",
        "\n",
        "        pred = ###\n",
        "\n",
        "        train_accuracy += accuracy_score(target.cpu().numpy(), pred.detach().cpu().numpy())*input.size(0)\n",
        "\n",
        "\n",
        "        ###                # Perform an optimisation step for all parameters and learning rate\n",
        "                                                            # defined in the construction of the optimiser\n",
        "\n",
        "    train_loss = train_loss / len(data_loader.dataset)      # Average loss over the whole dataset\n",
        "    train_accuracy = train_accuracy/len(data_loader.dataset)\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def valid(model, criterion, data_loader):\n",
        "    \" Equivalent to the training function without any backpropagation or optimisation steps\"\n",
        "    ###\n",
        "    valid_loss, valid_accuracy = 0, 0\n",
        "    with ###:\n",
        "        for input, target in data_loader:\n",
        "            input, target = input.to(device), target.to(device)\n",
        "\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            valid_loss += loss*input.size(0)\n",
        "\n",
        "            pred = output.softmax(dim=1).max(dim=1)[1]\n",
        "\n",
        "            valid_accuracy += accuracy_score(target.cpu().numpy(), pred.detach().cpu().numpy())*input.size(0)\n",
        "\n",
        "        valid_loss = valid_loss / len(data_loader.dataset)\n",
        "        valid_accuracy = valid_accuracy/len(data_loader.dataset)\n",
        "        return valid_loss, valid_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7I5S7DjBqhI"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "nepochs = 5\n",
        "for i in tqdm(range(nepochs)):\n",
        "    train_loss, train_accuracy = ###\n",
        "    valid_loss, valid_accuracy = ###\n",
        "\n",
        "    print(train_loss, train_accuracy)\n",
        "    log = {\"train_loss\": train_loss.item(), \"train_accuracy\": train_accuracy.item(),\n",
        "            \"valid_loss\": valid_loss.item(),  \"valid_accuracy\": valid_accuracy.item()}\n",
        "    print(log)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0Euhu1iJyZM"
      },
      "outputs": [],
      "source": [
        "print(first_param_layer.grad)\n",
        "print(first_param_layer.grad.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FqlXhtRBqhI"
      },
      "source": [
        "* What does the final layer of our model look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKwbG-5LBqhI"
      },
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "output = model(next(iter(train_loader))[0][:16].to(device))\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(###, cmap=\"plasma\", vmin=0., vmax=1.)\n",
        "plt.xticks([i for i in range(output.shape[1])])\n",
        "plt.xlabel(\"Labels\")\n",
        "plt.ylabel(\"Samples\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZuIsk5wBqhI"
      },
      "source": [
        "* The plot above shows that the final layer of our trained model shows the level of \"certainty\" over a predicted label. Some are a clear choice, but some others cast some doubt.\n",
        "\n",
        "---\n",
        "\n",
        "Some considerations:\n",
        "\n",
        "* ``model.train`` and ``model.eval`` control some underlying behaviours of the model that require different behaviours during training and inference time. For instance, ``batch normalisation`` layers no longer are activated for batch-statistics and ``dropout`` layers are deactivated (more on theses concepts in the upcoming lectures)\n",
        "\n",
        "* ``torch.no_grad`` disables any gradient computation in ``torch.Tensors`` temporarily. Practically, this means more efficiency in inference since the [computational graph](https://colah.github.io/posts/2015-08-Backprop/) of operations does not have to be retained.\n",
        "\n",
        "* ``.detach()`` returns a new tensor that is detached from the current computational graph (gradients can no longer be computed). This is particularly useful for processing the tensor with other libraries (e.g. numpy, scikit-learn, etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n5-iChmBqhI"
      },
      "source": [
        "## Deeper into ``Datasets``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuY6oRrBBqhI"
      },
      "source": [
        "* So far we have handled well-formated datasets that align very well with the ``torch`` library\n",
        "\n",
        "* But how can we handle datasets that we might find online, or develop ourselves, that require different formating structures?\n",
        "\n",
        "* ``ImageFolder`` is one useful base class provided by ``torchvision`` that relies on the following folder structure:\n",
        "\n",
        "```\n",
        "root/class_x/xxx.png\n",
        "root/class_x/xxy.png\n",
        "root/class_x/[...]/xxz.png\n",
        "\n",
        "root/class_y/123.png\n",
        "root/class_y/nsdf3.png\n",
        "root/class_y/[...]/asd932_.png\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX8kDvM4BqhI"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\" width=\"600\" height=\"700\"></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky9Lj-a0GCK8"
      },
      "source": [
        "* We will use a new dataset that is available on the [Kaggle](http://www.kaggle.com) platform\n",
        "\n",
        "* To run the following code you will need a Kaggle account and an authentication ``json`` file\n",
        "\n",
        "* To do so follow the 'Authentication' instructions on this link https://www.kaggle.com/docs/api\n",
        "\n",
        "* Once you downloaded the ``kaggle.json`` file, upload it to ``MyDrive``\n",
        "\n",
        "* You can use the snippet below to retrieve datasets from Kaggle in other projects as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDqpij32BqhI"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle\n",
        "\n",
        "!kaggle datasets download -d gpiosenka/butterfly-images40-species\n",
        "!mkdir ./butterfly-images40-species\n",
        "!unzip -q butterfly-images40-species.zip -d ./butterfly-images40-species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcpCE4c0BqhI"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "butterfly_train_dataset = ###\n",
        "\n",
        "print(butterfly_train_dataset, \"\\n\")\n",
        "print(butterfly_train_dataset.class_to_idx)\n",
        "\n",
        "butterfly, target = butterfly_train_dataset[42]\n",
        "plt.imshow(butterfly)\n",
        "plt.title(list(butterfly_train_dataset.class_to_idx)[target])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SpC6YrFBqhJ"
      },
      "source": [
        "* But we can also create our own dataset class to adapt to any data structure that we'd like.\n",
        "\n",
        "* We can do so by taking advantage of the ``Dataset`` class in ``PyTorch``, which can be used as an base class for custom datasets\n",
        "\n",
        "* From the documentation:\n",
        "\n",
        "```\n",
        "torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
        "\n",
        "__len__ so that len(dataset) returns the size of the dataset.\n",
        "\n",
        "__getitem__ to support the indexing such that dataset[i] can be used to get iith sample.\n",
        "\n",
        "```\n",
        "\n",
        "* Both methods are used by the ``Dataloader`` to sample the dataset. ``__getitem__`` returns a sample, and ``__len__`` defines the range in which ``__getitem__`` can be called.\n",
        "\n",
        "---\n",
        "\n",
        "* Let's now consider the same buttfly dataset, but instead of a classifiction problem, we are interested in a reconstruction one: deblurring.\n",
        "\n",
        "* We design our problem such that our input is a blurred version of our target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSCsGquLBqhJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from torchvision.transforms import GaussianBlur\n",
        "\n",
        "class BlurredButterflyDataset(###):\n",
        "  def __init__(self, root, kernel_size, sigma=(0.1, 2.0), transform=None):\n",
        "      self.transform = transform\n",
        "      self.root = root\n",
        "      self.kernel_size = kernel_size\n",
        "      self.sigma = sigma\n",
        "      self.data_paths = ###\n",
        "\n",
        "  def _get_image_paths(self, exts=(\".jpeg\", \".jpg\", \".png\")):\n",
        "      data_paths = []\n",
        "      for root, dirs, files in os.walk(self.root):\n",
        "          for file in files:\n",
        "              if(file.endswith(exts)):\n",
        "                  data_paths.append(os.path.join(root,file))\n",
        "      return data_paths\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      # Load image\n",
        "      ###\n",
        "\n",
        "      # Let's make to Tensor compulsory so we can manipulate the image as a tensor inside __getitem_\n",
        "      ###\n",
        "\n",
        "      # Apply other transforms\n",
        "      ###\n",
        "\n",
        "      # Blurred image\n",
        "      ###\n",
        "\n",
        "      return ###\n",
        "\n",
        "  def __len__(self):\n",
        "      return ###\n",
        "\n",
        "  def __str__(self):\n",
        "      class_string = \"\"\n",
        "      class_string += self.__class__.__name__\n",
        "      class_string+=\"\\n\\tlen : %d\"%self.__len__()\n",
        "      for key, value in self.__dict__.items():\n",
        "          if key != \"data_paths\":\n",
        "              class_string+=\"\\n\\t\" + str(key) + \" : \" + str(value)\n",
        "      return class_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlH44JCwBqhJ"
      },
      "outputs": [],
      "source": [
        "butterfly_train_dataset = ###\n",
        "print(butterfly_train_dataset)\n",
        "input, target = ###\n",
        "###\n",
        "\n",
        "plt.imshow(input.permute(1,2,0))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(target.permute(1,2,0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8kMoJRcBqhJ"
      },
      "source": [
        "## Further considerations\n",
        "\n",
        "* The options for customisation in ``Pytorch`` library are extensive. Mostly, you will **not** need to fully understand these concepts for a successful completion of this course.\n",
        "\n",
        "* The documentation of ``Pytorch`` is full of examples, tutorials and paper references and will be your best reference to learn new application concepts and how to implement them.\n",
        "\n",
        "* A few other considerations before we wrap up:\n",
        "\n",
        "Mathematical Utils in ``Pytorch``\n",
        "\n",
        "---\n",
        "[``torch.linalg``](https://pytorch.org/docs/stable/linalg.html)\n",
        "    - [``torch.fft``](https://pytorch.org/docs/stable/fft.html)\n",
        "    - [``torch.random``](https://pytorch.org/docs/stable/random.html)\n",
        "    - [``torch.sparse``](https://pytorch.org/docs/stable/sparse.html)\n",
        "    - ...\n",
        "\n",
        "\n",
        "Losses and Activations\n",
        "\n",
        "---\n",
        "\n",
        "The loss function drives the optimisation of machine learning models. It tells the model what it is meant to learn. In this sense, different tasks require different loss functions. In our examples so far, we have used ``CrossEntropy`` as our loss, which is well suited to multi-taks classification problems. In contrast, this loss function would not be suited, for example, to reconstruction problems. In this case we would require a loss function that would compare an image output to a target output. The ``MSELoss`` would be more suitable for this scenario. A wide range of loss functions are provided by ``Pytorch``, but it is up to you to decide which is more appropriate to your problem.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSzskbBCIDEs"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://pytorch.org/docs/stable/nn.html#loss-functions\" width=\"700\" height=\"500\"></iframe>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYQeCjWsBqhJ"
      },
      "source": [
        "Learning Rate Annealing\n",
        "\n",
        "---\n",
        "\n",
        "Learning rate annealing refers to decreasing the learning rate during the course of optimisation. This has been shown to help with convergence and stabilisation of your model, while also cutting training time. In ``Pytorch`` the implementation of learning rate annealing follows a similar syntax to the implementation of the optimiser, with different annealing strategies offered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5dV3FCyH87v"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\" width=\"700\" height=\"500\"></iframe>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJEY4_vCHtN3"
      },
      "source": [
        "Dataloader sampler\n",
        "\n",
        "---\n",
        "\n",
        "As with custom ``Dataset`` classes, we can also design better sampling strategies that are better suited to our dataset. This is an interesting way of adding or removing biases in our model. For instance, using a standard sampler for a dataset that has different amounts of data per class will bias our model to perform better to the classes that contain more samples. We can instead use a ``WeightedSampler`` to increase the probability of a weaker class to show up in our batches. As per usual, ``Pytorch`` offers a wide range of sampling strategies that can be passed into the ``Dataloader``, including a base ``Sampler`` class so we can customise our own.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "remz6yimH4Ul"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "\n",
        "<iframe src=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler\" width=\"700\" height=\"500\"></iframe>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0INKxBn7Hu1i"
      },
      "source": [
        "Model Initialisations\n",
        "\n",
        "---\n",
        "\n",
        "The initialisation of weights in our model can have significant impact on its convergence and performance. It is natural that ``Pytorch`` will also offer different ways to initialise the model weights. For most layers, the default initialisation method is the ``Kaiming Uniform``, which is described in the documentation:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqvik-txHseC"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_\" width=\"700\" height=\"500\"></iframe>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WttozpAEPvvE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b996dd704eec390d394e4eff83c8c73a7c6e40d054c583352c9aa3265aab441b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}